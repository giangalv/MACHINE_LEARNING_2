{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../content/input/\"\n",
    "\n",
    "try:\n",
    "    files = os.listdir(PATH)\n",
    "    print(\"Files in directory:\", files)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory '{PATH}' not found. Please check the path and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = pd.read_csv(os.path.join(PATH, 'X_train.csv'))\n",
    "X_test = pd.read_csv(os.path.join(PATH, 'X_test.csv'))\n",
    "y_train = pd.read_csv(os.path.join(PATH, 'y_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train X: {}\\nTrain y: {}\\nTest X: {}\".format(X_train.shape, y_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def missing_data(data):\n",
    "    total = data.isnull().sum()\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100)\n",
    "    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    types = []\n",
    "    for col in data.columns:\n",
    "        dtype = str(data[col].dtype)\n",
    "        types.append(dtype)\n",
    "    tt['Types'] = types\n",
    "    return(np.transpose(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize=(16,4))\n",
    "g = sns.countplot(y_train['surface'])\n",
    "g.set_title(\"Number of labels for each class\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distribution(df1, df2, label1, label2, features):\n",
    "    i = 0\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2,5,figsize=(16,8))\n",
    "\n",
    "    for feature in features:\n",
    "        i += 1\n",
    "        plt.subplot(2,5,i)\n",
    "        sns.kdeplot(df1[feature], bw=0.5,label=label1)\n",
    "        sns.kdeplot(df2[feature], bw=0.5,label=label2)\n",
    "        plt.xlabel(feature, fontsize=9)\n",
    "        locs, labels = plt.xticks()\n",
    "        plt.tick_params(axis='x', which='major', labelsize=8)\n",
    "        plt.tick_params(axis='y', which='major', labelsize=8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns.values[3:]\n",
    "plot_feature_distribution(X_train, X_test, 'train', 'test', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_class_distribution(classes,tt, features):\n",
    "    i = 0\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(5,2,figsize=(16,24))\n",
    "\n",
    "    for feature in features:\n",
    "        i += 1\n",
    "        plt.subplot(5,2,i)\n",
    "        for clas in classes:\n",
    "            ttc = tt[tt['surface']==clas]\n",
    "            sns.kdeplot(ttc[feature], bw=0.5,label=clas)\n",
    "        plt.xlabel(feature, fontsize=9)\n",
    "        locs, labels = plt.xticks()\n",
    "        plt.tick_params(axis='x', which='major', labelsize=8)\n",
    "        plt.tick_params(axis='y', which='major', labelsize=8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (y_train['surface'].value_counts()).index\n",
    "tt = X_train.merge(y_train, on='series_id', how='inner')\n",
    "plot_feature_class_distribution(classes, tt, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/53033620/how-to-convert-euler-angles-to-quaternions-and-get-the-same-euler-angles-back-fr?rq=1\n",
    "def quaternion_to_euler(x, y, z, w):\n",
    "    import math\n",
    "    t0 = +2.0 * (w * x + y * z)\n",
    "    t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "    X = math.atan2(t0, t1)\n",
    "\n",
    "    t2 = +2.0 * (w * y - z * x)\n",
    "    t2 = +1.0 if t2 > +1.0 else t2\n",
    "    t2 = -1.0 if t2 < -1.0 else t2\n",
    "    Y = math.asin(t2)\n",
    "\n",
    "    t3 = +2.0 * (w * z + x * y)\n",
    "    t4 = +1.0 - 2.0 * (y * y + z * z)\n",
    "    Z = math.atan2(t3, t4)\n",
    "\n",
    "    return X, Y, Z\n",
    "\n",
    "def perform_feature_engineering(actual):\n",
    "    new = pd.DataFrame()\n",
    "    actual['total_angular_velocity'] = (actual['angular_velocity_X'] ** 2 + actual['angular_velocity_Y'] ** 2 + actual['angular_velocity_Z'] ** 2) ** 0.5\n",
    "    actual['total_linear_acceleration'] = (actual['linear_acceleration_X'] ** 2 + actual['linear_acceleration_Y'] ** 2 + actual['linear_acceleration_Z'] ** 2) ** 0.5\n",
    "    \n",
    "    actual['acc_vs_vel'] = actual['total_linear_acceleration'] / actual['total_angular_velocity']\n",
    "    \n",
    "    x, y, z, w = actual['orientation_X'].tolist(), actual['orientation_Y'].tolist(), actual['orientation_Z'].tolist(), actual['orientation_W'].tolist()\n",
    "    nx, ny, nz = [], [], []\n",
    "    for i in range(len(x)):\n",
    "        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n",
    "        nx.append(xx)\n",
    "        ny.append(yy)\n",
    "        nz.append(zz)\n",
    "    \n",
    "    actual['euler_x'] = nx\n",
    "    actual['euler_y'] = ny\n",
    "    actual['euler_z'] = nz\n",
    "    \n",
    "    actual['total_angle'] = (actual['euler_x'] ** 2 + actual['euler_y'] ** 2 + actual['euler_z'] ** 2) ** 5\n",
    "    actual['angle_vs_acc'] = actual['total_angle'] / actual['total_linear_acceleration']\n",
    "    actual['angle_vs_vel'] = actual['total_angle'] / actual['total_angular_velocity']\n",
    "    \n",
    "    def mean_change_of_abs_change(x):\n",
    "        return np.mean(np.diff(np.abs(np.diff(x))))\n",
    "\n",
    "    def mean_abs_change(x):\n",
    "        return np.mean(np.abs(np.diff(x)))\n",
    "    \n",
    "    for col in actual.columns:\n",
    "        if col in ['row_id', 'series_id', 'measurement_number']:\n",
    "            continue\n",
    "        new[col + '_mean'] = actual.groupby(['series_id'])[col].mean()\n",
    "        new[col + '_min'] = actual.groupby(['series_id'])[col].min()\n",
    "        new[col + '_max'] = actual.groupby(['series_id'])[col].max()\n",
    "        new[col + '_std'] = actual.groupby(['series_id'])[col].std()\n",
    "        new[col + '_max_to_min'] = new[col + '_max'] / new[col + '_min']\n",
    "        \n",
    "        # Change. 1st order.\n",
    "        new[col + '_mean_abs_change'] = actual.groupby('series_id')[col].apply(mean_abs_change)\n",
    "        \n",
    "        # Change of Change. 2nd order.\n",
    "        new[col + '_mean_change_of_abs_change'] = actual.groupby('series_id')[col].apply(mean_change_of_abs_change)\n",
    "        \n",
    "        new[col + '_abs_max'] = actual.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n",
    "        new[col + '_abs_min'] = actual.groupby('series_id')[col].apply(lambda x: np.min(np.abs(x)))\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = perform_feature_engineering(X_train)\n",
    "X_test = perform_feature_engineering(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train['surface'] = le.fit_transform(y_train['surface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(0, inplace = True)\n",
    "X_train.replace(-np.inf, 0, inplace = True)\n",
    "X_train.replace(np.inf, 0, inplace = True)\n",
    "X_test.fillna(0, inplace = True)\n",
    "X_test.replace(-np.inf, 0, inplace = True)\n",
    "X_test.replace(np.inf, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "#               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "#               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "#               'bootstrap': bootstrap\n",
    "              }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 800, 'min_samples_leaf': 1, 'max_depth': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds_rf = np.zeros((X_test.shape[0], 9))\n",
    "oof_preds_rf = np.zeros((X_train.shape[0]))\n",
    "score = 0\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train['surface'])):\n",
    "    clf =  RandomForestClassifier(**params)\n",
    "    #rf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    #rf_random.fit(X_train.iloc[trn_idx], y_train['surface'][trn_idx])\n",
    "    #print(rf_random.best_params_)\n",
    "    #clf = rf_random.best_estimator_\n",
    "    clf.fit(X_train.iloc[trn_idx], y_train['surface'][trn_idx])\n",
    "    oof_preds_rf[val_idx] = clf.predict(X_train.iloc[val_idx])\n",
    "    sub_preds_rf += clf.predict_proba(X_test) / folds.n_splits\n",
    "    score += clf.score(X_train.iloc[val_idx], y_train['surface'][val_idx])\n",
    "    print('Fold: {} score: {}'.format(fold_,clf.score(X_train.iloc[val_idx], y_train['surface'][val_idx])))\n",
    "print('Avg Accuracy', score / folds.n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(PATH,'sample_submission.csv'))\n",
    "submission['surface'] = le.inverse_transform(sub_preds_rf.argmax(axis=1))\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
